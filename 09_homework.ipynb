{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371970ff",
   "metadata": {},
   "source": [
    "# Домашнее задание № 3. Исправление опечаток"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cf8bd",
   "metadata": {},
   "source": [
    "## 1. Учет грамматики при оценке исправлений (3 балла)\n",
    "\n",
    "В последнюю итерацию алгоритма для генерации исправлений добавьте еще один компонент - учет грамматической информации. Частично она уже учитывается за счет языковой модели (вероятность предсказывается для словоформы), но такой подход ограничен из-за того, что модель не может ничего предсказать для словоформ, которых не было в обучающей выборке. Чтобы это исправить постройте еще одну \"языковую модель\" на грамматических тэгах:\n",
    "1) Используя mystem или pymorphy, разметьте какой-нибудь корпус (например, кусок wiki из семинара) или воспользуйтесь уже размеченным корпусом (например, opencorpora)\n",
    "2) соберите униграмные и биграмные статистики на уровне грамматических тэгов (например, вместо `задача важна` у вас будет биграм `S,жен,неод=им,ед A=ед,кр,жен`). Для простоты можете начать только с частеречных тэгов и добавить остальную информацию позже\n",
    "3) напишите функцию, которая будет оценивать вероятность данного предложения на основе грамматической языковой модели (статистик из предыдущего шага). Функция должна сначала преобразовать текст в грамматические тэги, используя точно такой же подход, что использовался на шаге 1. \n",
    "4) в функции correct_text_with_lm замените compute_sentence_proba на вашу новую функцию и прогоните получившийся алгоритм на данных\n",
    "5) сравните предсказания с предсказанием изначального correct_text_with_lm, проверьте метрики и посмотрите на различие в ошибках и исправлениях, найдите несколько примеров отличий в предсказаниях этих подходов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e67f8d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712d0328ace444798696ffac80d9dc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
      "INFO:stanza:Downloading default packages for language: ru (Russian) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902855c1601d4e2faeb9ed280d0295ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.11.0/models/default.zip:   0%|          | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /root/stanza_resources/ru/default.zip\n",
      "INFO:stanza:Finished downloading models and saved to /root/stanza_resources\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import stanza\n",
    "import textdistance\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "stanza.download('ru')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8c36b",
   "metadata": {},
   "source": [
    "### 1. Загрузка данных\n",
    "\n",
    "Я решил использовать уже размеченный корпус в качестве словаря (и для слов, и для тегов) — а именно, Sintagrus. Он размечен в UD, поэтому для разметки наших данных с опечатками мы будем использовать Stanza — там русская модель натренирована на том же самом корпусе, то есть результат будет максимально консистентный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e449a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Синтагрус\n",
    "!wget -q https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n",
    "!wget -q https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-test.conllu\n",
    "!wget -q https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-a.conllu\n",
    "!wget -q https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-b.conllu\n",
    "\n",
    "# Данные с опечатками\n",
    "!wget -q https://github.com/mannefedov/compling_nlp_hse_course/raw/master/notebooks/spelling/data.zip\n",
    "!unzip -o -q data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb1752",
   "metadata": {},
   "source": [
    "### 2. Парсим корпус и собираем статистики\n",
    "\n",
    "В качестве тегов для биграмм будем использовать и часть речи, и все фичи (только значения, без названий), отсортированные по алфавиту. Соединим это всё запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cbb2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список файлов корпуса\n",
    "conllu_files = [\n",
    "    'ru_syntagrus-ud-dev.conllu',\n",
    "    'ru_syntagrus-ud-test.conllu',\n",
    "    'ru_syntagrus-ud-train-a.conllu',\n",
    "    'ru_syntagrus-ud-train-b.conllu'\n",
    "]\n",
    "\n",
    "vocab = Counter()\n",
    "word_unigrams = Counter()\n",
    "word_bigrams = Counter()\n",
    "tag_unigrams = Counter()\n",
    "tag_bigrams = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e610e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conllu_features(pos, feats_str):\n",
    "    # Если фич нет, возвращаем только POS\n",
    "    if feats_str == '_' or not feats_str:\n",
    "        return pos\n",
    "\n",
    "    feats = [f.split('=') for f in feats_str.split('|') if '=' in f]\n",
    "    feats.sort(key=lambda x: x[0])  # Сортировка по имени фичи (Key)\n",
    "\n",
    "    feat_values = [f[1] for f in feats]\n",
    "\n",
    "    return pos + ',' + ','.join(feat_values)\n",
    "\n",
    "\n",
    "def get_ngrams(sequence, n=2):\n",
    "    return [' '.join(sequence[i:i + n]) for i in range(len(sequence) - n + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e42912",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in conllu_files:\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        current_sent_words = []\n",
    "        current_sent_tags = []\n",
    "\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Пропускаем комментарии\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "\n",
    "            # Пустая строка - конец предложения\n",
    "            if not line:\n",
    "                if current_sent_words:\n",
    "                    # Добавляем маркеры начала и конца\n",
    "                    full_words = ['<start>'] + current_sent_words + ['<end>']\n",
    "                    full_tags = ['<start>'] + current_sent_tags + ['<end>']\n",
    "\n",
    "                    # Обновляем статистики\n",
    "                    # Словарь без спецсимволов\n",
    "                    vocab.update(current_sent_words)\n",
    "                    word_unigrams.update(full_words)\n",
    "                    word_bigrams.update(get_ngrams(full_words))\n",
    "\n",
    "                    tag_unigrams.update(full_tags)\n",
    "                    tag_bigrams.update(get_ngrams(full_tags))\n",
    "\n",
    "                    current_sent_words = []\n",
    "                    current_sent_tags = []\n",
    "                continue\n",
    "\n",
    "            # Парсинг токена\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) != 10:\n",
    "                continue\n",
    "\n",
    "            word = parts[1].lower()\n",
    "            pos = parts[3]\n",
    "            feats = parts[5]\n",
    "\n",
    "            # Игнорируем пунктуацию\n",
    "            if pos == 'PUNCT':\n",
    "                continue\n",
    "\n",
    "            # Формируем тэг\n",
    "            full_tag = parse_conllu_features(pos, feats)\n",
    "\n",
    "            current_sent_words.append(word)\n",
    "            current_sent_tags.append(full_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65649eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря слов: 121389\n",
      "Пример биграммы тегов: [('<start> ADP', 10846), ('<start> CCONJ', 6913), ('ADJ,Gen,Pos,Fem,Sing NOUN,Inan,Gen,Fem,Sing', 6088), ('ADP NOUN,Inan,Loc,Masc,Sing', 5255), ('<start> ADV,Pos', 5022), ('ADJ,Gen,Pos,Masc,Sing NOUN,Inan,Gen,Masc,Sing', 4877), ('ADP NOUN,Inan,Loc,Fem,Sing', 4689), ('ADJ,Nom,Pos,Fem,Sing NOUN,Inan,Nom,Fem,Sing', 4417), ('NOUN,Inan,Gen,Fem,Sing <end>', 4101), ('ADJ,Nom,Pos,Masc,Sing NOUN,Inan,Nom,Masc,Sing', 3949)]\n"
     ]
    }
   ],
   "source": [
    "# Подсчет общего количества для вероятностей\n",
    "N_words = sum(word_unigrams.values())\n",
    "N_tags = sum(tag_unigrams.values())\n",
    "\n",
    "print(f\"Размер словаря слов: {len(vocab)}\")\n",
    "print(f\"Пример биграммы тегов: {list(tag_bigrams.most_common(10))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967cb79",
   "metadata": {},
   "source": [
    "### 3. Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf67a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = list(vocab.keys())\n",
    "id2word = {i: word for i, word in enumerate(word2id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5a5a9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность матрицы: (121389, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Векторизация по символам (1-3 граммы)\n",
    "vec = CountVectorizer(analyzer='char', max_features=10000, ngram_range=(1, 3))\n",
    "X = vec.fit_transform(word2id)\n",
    "\n",
    "print(f\"Размерность матрицы: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d437d",
   "metadata": {},
   "source": [
    "### 4. Препроцессинг тестовых данных\n",
    "\n",
    "Stanza самостоятельно умеет токенизировать, поэтому эти токены мы будем использовать для выравнивания, игнорируя только пунктуацию. При этом мы передаём все предложения разом, в виде одного документа, и отключаем в токенизаторе деления на предложения (то есть указываем, что текст на предложения уже разбит) — POS-теггинг и присвоение морфологических фич тогда выполнятся относительно быстро, правда, только на GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "562780ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_full = stanza.Pipeline(\n",
    "    lang='ru',\n",
    "    tokenize_no_ssplit=True,\n",
    "    verbose=False)\n",
    "nlp_tokenize = stanza.Pipeline(\n",
    "    lang='ru',\n",
    "    processors='tokenize',\n",
    "    tokenize_no_ssplit=True,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a683eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sents_with_mistakes.txt', 'r', encoding='utf-8') as f:\n",
    "    bad_lines = f.read().splitlines()\n",
    "\n",
    "with open('correct_sents.txt', 'r', encoding='utf-8') as f:\n",
    "    true_lines = f.read().splitlines()\n",
    "\n",
    "bad_text_formatted = \"\\n\\n\".join(bad_lines)\n",
    "true_text_formatted = \"\\n\\n\".join(true_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16e3065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed bad sentences: 915\n",
      "Processed true sentences: 915\n"
     ]
    }
   ],
   "source": [
    "# Обработка текстов с опечатками\n",
    "doc_bad = nlp_full(bad_text_formatted)\n",
    "doc_true = nlp_tokenize(true_text_formatted)\n",
    "\n",
    "print(f\"Processed bad sentences: {len(doc_bad.sentences)}\")\n",
    "print(f\"Processed true sentences: {len(doc_true.sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19bf20",
   "metadata": {},
   "source": [
    "### 5. Всякие полезные функции с семинара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4104f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_with_metric(\n",
    "        text,\n",
    "        lookup,\n",
    "        topn=20,\n",
    "        metric=textdistance.levenshtein):\n",
    "    similarities = Counter()\n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.similarity(text, word)\n",
    "    return similarities.most_common(topn)\n",
    "\n",
    "\n",
    "def get_closest_match_vec(text, X, vec, topn=20):\n",
    "    # Векторизуем входное слово\n",
    "    v = vec.transform([text])\n",
    "    # Считаем косинусное расстояние до всех слов словаря\n",
    "    similarities = cosine_distances(v, X)[0]\n",
    "    # Берем индексы топ-N ближайших\n",
    "    top_indices = similarities.argsort()[:topn]\n",
    "    return [(id2word[idx], similarities[idx]) for idx in top_indices]\n",
    "\n",
    "\n",
    "def get_closest_hybrid_match(\n",
    "        text,\n",
    "        X,\n",
    "        vec,\n",
    "        topn=3,\n",
    "        metric=textdistance.damerau_levenshtein):\n",
    "    # Отбираем кандидатов по косинусному расстоянию (с запасом *4)\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn * 4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "\n",
    "    # Ранжируем их по метрике (Дамерау-Левенштейн)\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    return closest\n",
    "\n",
    "\n",
    "def predict_mistaken(word, vocab):\n",
    "    # 0 если слово есть в словаре, 1 если нет\n",
    "    return 0 if word in vocab else 1\n",
    "\n",
    "\n",
    "def compute_word_proba(tokens):\n",
    "    prob = 0\n",
    "    seq = ['<start>'] + [t for t in tokens if t] + ['<end>']\n",
    "    ngrams = get_ngrams(seq, 2)\n",
    "\n",
    "    for ngram in ngrams:\n",
    "        w1, w2 = ngram.split()\n",
    "        if ngram in word_bigrams and w1 in word_unigrams:\n",
    "            prob += np.log(word_bigrams[ngram] / word_unigrams[w1])\n",
    "        else:\n",
    "            prob += np.log(1e-10)  # Штраф за неизвестную биграмму\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0210a7c",
   "metadata": {},
   "source": [
    "### 6. Сбор известных тегов для слов из корпуса и подсчёт вероятности\n",
    "\n",
    "Сделаем кэш, чтобы хранить теги для наших слов из словаря, во время подсчёта вероятности будем брать самый вероятный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3de70c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tags_cache = defaultdict(Counter)\n",
    "\n",
    "for filepath in conllu_files:\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) != 10:\n",
    "                continue\n",
    "\n",
    "            if parts[3] == 'PUNCT':\n",
    "                continue\n",
    "\n",
    "            word = parts[1].lower()\n",
    "            tag = parse_conllu_features(parts[3], parts[5])\n",
    "\n",
    "            word_tags_cache[word][tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd098b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tag_proba(tags):\n",
    "    prob = 0\n",
    "    seq = ['<start>'] + tags + ['<end>']\n",
    "\n",
    "    for i in range(len(seq) - 1):\n",
    "        bigram = f\"{seq[i]} {seq[i + 1]}\"\n",
    "        t1 = seq[i]\n",
    "\n",
    "        if bigram in tag_bigrams and t1 in tag_unigrams:\n",
    "            prob += np.log(tag_bigrams[bigram] / tag_unigrams[t1])\n",
    "        else:\n",
    "            prob += np.log(1e-10)  # Штраф за неизвестную биграмму\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccec6632",
   "metadata": {},
   "source": [
    "### 7. Наш пайплайн исправления опечаток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db20c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_spell_check(stanza_doc, lm_type='tag', limit=None):\n",
    "    corrected_sentences = []\n",
    "\n",
    "    # Берем срез предложений, если задан лимит\n",
    "    sentences = stanza_doc.sentences[:limit] if limit else stanza_doc.sentences\n",
    "\n",
    "    for sent in tqdm(sentences):\n",
    "        token_options = []\n",
    "\n",
    "        for token in sent.tokens:\n",
    "            word_obj = token.words[0]\n",
    "            text = word_obj.text\n",
    "            lower = text.lower()\n",
    "\n",
    "            # Пунктуация\n",
    "            if word_obj.upos == 'PUNCT':\n",
    "                token_options.append([(text, None)])\n",
    "                continue\n",
    "\n",
    "            # Проверка на ошибку\n",
    "            if predict_mistaken(lower, vocab):\n",
    "                preds = get_closest_hybrid_match(lower, X, vec)\n",
    "                candidates = [p[0] for p in preds]\n",
    "                candidates.append(lower)\n",
    "                candidates = list(set(candidates))\n",
    "\n",
    "                # Для каждого кандидата находим его возможные теги\n",
    "                cand_options = []\n",
    "                for cand in candidates:\n",
    "                    possible_tags = word_tags_cache.get(cand, Counter())\n",
    "                    if possible_tags:\n",
    "                        best_tag = possible_tags.most_common(1)[0][0]\n",
    "                        cand_options.append((cand, best_tag))\n",
    "                    else:\n",
    "                        original_tag = parse_conllu_features(\n",
    "                            word_obj.upos, word_obj.feats)\n",
    "                        cand_options.append((cand, original_tag))\n",
    "\n",
    "                token_options.append(cand_options)\n",
    "\n",
    "            # Слово правильное\n",
    "            else:\n",
    "                tag = parse_conllu_features(word_obj.upos, word_obj.feats)\n",
    "                token_options.append([(lower, tag)])\n",
    "\n",
    "        # Генерируем все комбинации предложений\n",
    "        best_sent_str = \"\"\n",
    "        best_score = -float('inf')\n",
    "\n",
    "        for p in itertools.product(*token_options):\n",
    "            # Формируем список слов для итогового предложения\n",
    "            words = [x[0] for x in p]\n",
    "\n",
    "            score = 0\n",
    "            if lm_type == 'tag':\n",
    "                tags_seq = [x[1] for x in p if x[1] is not None]\n",
    "                score = compute_tag_proba(tags_seq)\n",
    "            else:\n",
    "                words_seq = [x[0] for x in p if x[1] is not None]\n",
    "                score = compute_word_proba(words_seq)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_sent_str = \" \".join(words)\n",
    "\n",
    "        corrected_sentences.append(best_sent_str)\n",
    "\n",
    "    return corrected_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0fdc83",
   "metadata": {},
   "source": [
    "### 8. Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48ef3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_stanza(doc_true, doc_bad, predicted_strs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_mistaken = 0\n",
    "    mistaken_fixed = 0\n",
    "    total_correct = 0\n",
    "    correct_broken = 0\n",
    "\n",
    "    for i in range(len(doc_true.sentences)):\n",
    "        true_tokens = [t.words[0].text.lower(\n",
    "        ) for t in doc_true.sentences[i].tokens if t.words[0].upos != 'PUNCT']\n",
    "        bad_tokens = [t.words[0].text.lower(\n",
    "        ) for t in doc_bad.sentences[i].tokens if t.words[0].upos != 'PUNCT']\n",
    "\n",
    "        # Предсказание мы сплитим просто по пробелам (так как мы собирали его join-ом)\n",
    "        # Нужно тоже убрать пунктуацию, если она попала в строку\n",
    "        pred_tokens = [t.strip('«»—…“”\".,?!:')\n",
    "                       for t in predicted_strs[i].split()]\n",
    "        pred_tokens = [t for t in pred_tokens if t]  # убираем пустые\n",
    "\n",
    "        min_len = min(len(true_tokens), len(bad_tokens), len(pred_tokens))\n",
    "\n",
    "        for j in range(min_len):\n",
    "            t = true_tokens[j]\n",
    "            b = bad_tokens[j]\n",
    "            p = pred_tokens[j]\n",
    "\n",
    "            if t == p:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "            if t != b:  # Была ошибка\n",
    "                total_mistaken += 1\n",
    "                if t == p:\n",
    "                    mistaken_fixed += 1\n",
    "            else:  # Было верно\n",
    "                total_correct += 1\n",
    "                if t != p:\n",
    "                    correct_broken += 1\n",
    "\n",
    "    return {\n",
    "        \"total_accuracy\": correct /\n",
    "        total if total > 0 else 0,\n",
    "        \"fixed_mistakes\": mistaken_fixed /\n",
    "        total_mistaken if total_mistaken > 0 else 0,\n",
    "        \"broken_correct_words\": correct_broken /\n",
    "        total_correct if total_correct > 0 else 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66364b67",
   "metadata": {},
   "source": [
    "### 9. Бейзлайн: без грамматических тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fa7478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Correction with Word LM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813c5bfab0dc49a28acead47f8739519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics (Word LM):\n",
      "{'total_accuracy': 0.7350359138068635, 'fixed_mistakes': 0.37830858618463525, 'broken_correct_words': 0.19976401179941003}\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Correction with Word LM...\")\n",
    "preds_word = solve_spell_check(doc_bad, lm_type='word')\n",
    "\n",
    "metrics_word = calculate_metrics_stanza(doc_true, doc_bad, preds_word)\n",
    "print(\"\\nMetrics (Word LM):\")\n",
    "print(metrics_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b2e6a",
   "metadata": {},
   "source": [
    "### 10. Коррекция с учётом грамматики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bd0f7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Correction with Tag LM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b58e9d6e26040a4bbdb3d7e0b563f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics (Tag LM):\n",
      "{'total_accuracy': 0.7362330407023144, 'fixed_mistakes': 0.2588766946417043, 'broken_correct_words': 0.17651917404129794}\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Correction with Tag LM...\")\n",
    "preds_tag = solve_spell_check(doc_bad, lm_type='tag')\n",
    "\n",
    "metrics_tag = calculate_metrics_stanza(doc_true, doc_bad, preds_tag)\n",
    "print(\"\\nMetrics (Tag LM):\")\n",
    "print(metrics_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae2c49a",
   "metadata": {},
   "source": [
    "### 11. Посмотрим на различия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88821084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric                    | Word LM    | Tag LM    \n",
      "--------------------------------------------------\n",
      "total_accuracy            | 0.7350     | 0.7362\n",
      "fixed_mistakes            | 0.3783     | 0.2589\n",
      "broken_correct_words      | 0.1998     | 0.1765\n",
      "\n",
      "Examples of differences:\n",
      "--------------------------------------------------\n",
      "Original:  Симпатичнейшое шпионское устройство, такой себе гламурный фотоаппарат девушки Бонда - миниатюрная модель камеры Superheadz Clap Camera.\n",
      "Word LM:   симпатичный чемпионское устройство , такой себе гламурные фотоаппарат девушки бонда - миниатюрная модель камеры superjob clap america .\n",
      "Tag LM:    симпатичнейшое шпионское устройство , такой себе гламурный фотоаппарат девушки бонда - миниатюрная модель камеры superjob la america .\n",
      "Reference: Симпатичнейшее шпионское устройство такой себе гламурный фотоаппарат девушки Бонда миниатюрная модель камеры Superheadz Clap Camera\n",
      "--------------------------------------------------\n",
      "Original:  Опофеозом дня для меня сегодня стала фраза услышанная в новостях:\n",
      "Word LM:   апофеозом дня для меня сегодня стала фраза услышанное в новостных :\n",
      "Tag LM:    апофеоз дня для меня сегодня стала фраза усыпанная в новостях :\n",
      "Reference: Апофеозом дня для меня сегодня стала фраза услышанная в новостях\n",
      "--------------------------------------------------\n",
      "Original:  Нащщот Чавеса разве что не соглашусь.\n",
      "Word LM:   оснащенной завеса разве что не соглашусь .\n",
      "Tag LM:    нащщот завеса разве что не соглашусь .\n",
      "Reference: Насчет Чавеса разве что не соглашусь\n",
      "--------------------------------------------------\n",
      "Original:  Многие сетуют на отсуствие \" живого взаимодействия между учеником и учителем \" - а в чем оно по сути?\n",
      "Word LM:   многие сетуют на отсутствие \" живого взаимодействия между учеником и учителем \" - а в чем оно по сути ?\n",
      "Tag LM:    многие сетуют на отсутствии \" живого взаимодействия между учеником и учителем \" - а в чем оно по сути ?\n",
      "Reference: Многие сетуют на отсутствие живого взаимодействия между учеником и учителем а в чем оно по сути\n",
      "--------------------------------------------------\n",
      "Original:  Основая цель мероприятия - практическая отработка навыков по оказанию помощи гражданам, попавшим в ДТП, а также повышение и совершенствование уровня профессиональной подготовки сотрудников МЧС при проведении аварийно-спасательных работ по ликвидации последствий дорожно-транспортных происшествий, сокращение временных показателей реагирования.\n",
      "Word LM:   основа цель мероприятия - практическая отработка навыков по оказанию помощи гражданам , попавшим в дтп , а также повышение и совершенствование уровня профессиональной подготовки сотрудников мчс при проведении аварийно - спасательных работ по ликвидации последствий дорожно - транспортных происшествий , сокращение временных показателей реагирования .\n",
      "Tag LM:    сосновая цель мероприятия - практическая отработка навыков по оказанию помощи гражданам , попавшим в дтп , а также повышение и совершенствование уровня профессиональной подготовки сотрудников мчс при проведении аварийно - спасательных работ по ликвидации последствий судорожно - транспортных происшествий , сокращение временных показателей реагирования .\n",
      "Reference: Основная цель мероприятия практическая отработка навыков по оказанию помощи гражданам попавшим в ДТП а также повышение и совершенствование уровня профессиональной подготовки сотрудников МЧС при проведении аварийно-спасательных работ по ликвидации последствий дорожно-транспортных происшествий сокращение временных показателей реагирования\n",
      "--------------------------------------------------\n",
      "Original:  вобщем как вы знаете из моего не давнего поста я жаловался на пропажу писем с моего ящека на почте.ру\n",
      "Word LM:   вобщем как вы знаете из моего не давнего поста я жаловался на продажу писем с моего ека на почте\n",
      "Tag LM:    обобщением как вы знаете из моего не давнего поста я жаловался на пропажу писем с моего ящека на почте.ру\n",
      "Reference: в общем как вы знаете из моего недавнего поста я жаловался на пропажу писем с моего ящика на почте.ру\n",
      "--------------------------------------------------\n",
      "Original:  Сегодяшнее утро выдалось просто волшебным.\n",
      "Word LM:   сегодняшнее утро выдалось просто волшебному .\n",
      "Tag LM:    сегодяшнее утро выдалось просто волшебный .\n",
      "Reference: Сегодняшнее утро выдалось просто волшебным\n",
      "--------------------------------------------------\n",
      "Original:  хороше что на выходгых не было стен, только деревья да ручьи...\n",
      "Word LM:   хорошее что на выходных не было стен , только деревья да ручьи . . .\n",
      "Tag LM:    хороше что на выходгых не было стен , только деревья да ручьи . . .\n",
      "Reference: хорошо что на выходных не было стен только деревья да ручьи\n",
      "--------------------------------------------------\n",
      "Original:  А Рите снятся сны, в которых меня убивают, патаму шта я пытаюсь всех спасти.\n",
      "Word LM:   а верите снятся сны , в которых меня убивают , аппаратами штаб я пытаюсь всех спасти .\n",
      "Tag LM:    а крите снятся сны , в которых меня убивают , патаму шта я пытаюсь всех спасти .\n",
      "Reference: А Рите снятся сны в которых меня убивают потому что я пытаюсь всех спасти\n",
      "--------------------------------------------------\n",
      "Original:  Лчше б этот бунт эритроцитов переждать в дубраве люминала,\n",
      "Word LM:   лучше б этот бунт эритроцитов переждать в траве иллюминатора ,\n",
      "Tag LM:    лчше б этот бунт эритроцитов переждать в управе люминала ,\n",
      "Reference: Лучше б этот бунт эритроцитов переждать в дубраве люминала\n",
      "--------------------------------------------------\n",
      "Original:  Поффтыкав в аэропорту поехали к билетным кассам где я взял билет на поезд.\n",
      "Word LM:   кофты в аэропорту поехали к балетным кассам где я взял билет на поезд .\n",
      "Tag LM:    поффтыкав в аэропорту поехали к билетными классами где я взял билет на поезд .\n",
      "Reference: Повтыкав в аэропорту поехали к билетным кассам где я взял билет на поезд\n",
      "--------------------------------------------------\n",
      "Original:  а днем мама снится как будто мы с ней в соре и она мне чтото выговаривает...\n",
      "Word LM:   а днем мама снится как будто мы с ней в ссоре и она мне что-то оговаривает . . .\n",
      "Tag LM:    а днем мама снится как будто мы с ней в соре и она мне что-то оговаривает . . .\n",
      "Reference: а днем мама снится как будто мы с ней в ссоре и она мне что-то выговаривает\n",
      "--------------------------------------------------\n",
      "Original:  Мошный лазер - в нерабочем состоянии - 350 кредиток.\n",
      "Word LM:   роскошный лазер - в неработающего состоянии - 350 кредитор .\n",
      "Tag LM:    роскошный лазер - в нерабочем состоянии - 350 кредитов .\n",
      "Reference: Мощный лазер в нерабочем состоянии 350 кредиток\n",
      "--------------------------------------------------\n",
      "Original:  хороше когда каждый год как первый...\n",
      "Word LM:   хорошее когда каждый год как первый . . .\n",
      "Tag LM:    хороше когда каждый год как первый . . .\n",
      "Reference: хорошо когда каждый год как первый\n",
      "--------------------------------------------------\n",
      "Original:  Особенно мне интересны Капулетти, включая и прислужницу Кормилицу, и молодеж которая будет учавствовать в поединках.\n",
      "Word LM:   особенно мне интересны капулетти , включая и прислушивались кормили , и молодежь которая будет участвовать в поединке .\n",
      "Tag LM:    особенно мне интересны рулетка , включая и прислуживать кормилец , и молодежь которая будет соучаствовать в поединке .\n",
      "Reference: Особенно мне интересны Капулетти включая и прислужницу Кормилицу и молодежь которая будет участвовать в поединках\n",
      "--------------------------------------------------\n",
      "Original:  седня должен был на работу притащиться программист и вешать всем оплеух, причем бОльшую часть на меня!\n",
      "Word LM:   средняя должен был на работу притащить программист и вешать всем оплеух , причем большую часть на меня !\n",
      "Tag LM:    седня должен был на работу притащить программист и вешать всем оплеух , причем большую часть на меня !\n",
      "Reference: сегодня должен был на работу притащиться программист и навешать всем оплеух причем большую часть на меня\n",
      "--------------------------------------------------\n",
      "Original:  Отвественность за реализацию, естественно, лежит на контрактных пивоварах.\n",
      "Word LM:   ответственность за реализацию , естественно , лежит на контрактный пивовары .\n",
      "Tag LM:    отвественность за реализацию , естественно , лежит на контрактных пивоварах .\n",
      "Reference: Ответственность за реализацию естественно лежит на контрактных пивоварах\n",
      "--------------------------------------------------\n",
      "Original:  Эстония, эт канешна не Португалия, но 4:0 тоже результат!\n",
      "Word LM:   эстония , эт жанена не португалия , но 4 : 0 тоже результат !\n",
      "Tag LM:    эстония , эт канешна не португалия , но 4 : 0 тоже результат !\n",
      "Reference: Эстония это конечно не Португалия но 4:0 тоже результат\n",
      "--------------------------------------------------\n",
      "Original:  Начальнег зажог павзрослому: всю предудущую неделю ходил покрытый прыщами, а с понедельника слег - ветрянка.\n",
      "Word LM:   начальная зажатого павзрослому : всю предудущую неделю ходил покрытый пирамидами , а с понедельника слег - ветряк .\n",
      "Tag LM:    начальнег зажог по-взрослому : всю предудущую неделю ходил покрытый прыжками , а с понедельника слегка - ветрянка .\n",
      "Reference: Начальник зажег по-взрослому всю предыдущую неделю ходил покрытый прыщами а с понедельника слег ветрянка\n",
      "--------------------------------------------------\n",
      "Original:  Подсаживаеться женшина - иностранка из Норвегии, она приглашает меня танцевать, оказывается что это место слишком крутое для меня, я загруживаюсь и больше в этот вечер не танцую...\n",
      "Word LM:   подсаживаеться женщинам - иностранка из норвегии , она приглашает меня танцевать , оказывается что это место слишком круто для меня , я загруживаюсь и больше в этот вечер не танцую . . .\n",
      "Tag LM:    подстраивается женщина - иностранка из норвегии , она приглашает меня танцевать , оказывается что это место слишком круто для меня , я загруживаюсь и больше в этот вечер не танцуют . . .\n",
      "Reference: Подсаживается женщина иностранка из Норвегии она приглашает меня танцевать оказывается что это место слишком крутое для меня я загруживаюсь и больше в этот вечер не танцую\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Metric':<25} | {'Word LM':<10} | {'Tag LM':<10}\")\n",
    "print(\"-\" * 50)\n",
    "for k in metrics_word:\n",
    "    print(f\"{k:<25} | {metrics_word[k]:.4f}     | {metrics_tag[k]:.4f}\")\n",
    "\n",
    "print(\"\\nExamples of differences:\")\n",
    "print(\"-\" * 50)\n",
    "count = 0\n",
    "for i in range(len(preds_word)):\n",
    "    if preds_word[i] != preds_tag[i]:\n",
    "        orig_text = doc_bad.sentences[i].text\n",
    "        true_text = doc_true.sentences[i].text\n",
    "\n",
    "        print(f\"Original:  {orig_text}\")\n",
    "        print(f\"Word LM:   {preds_word[i]}\")\n",
    "        print(f\"Tag LM:    {preds_tag[i]}\")\n",
    "        print(f\"Reference: {true_text}\")\n",
    "        print(\"-\" * 50)\n",
    "        count += 1\n",
    "        if count >= 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8336a6",
   "metadata": {},
   "source": [
    "### 12. И что в итоге?\n",
    "\n",
    "Стоит начать с того, что словарь, получившийся из Синтагруса, примерно в три раза меньше словаря Википедии, который был на семинаре. Поэтому качество в целом ниже независимо от метода.\n",
    "\n",
    "Если сравнивать два метода, метод Word LM с семинара отработал лучше — он исправил больше ошибок. Однако он же и показал больше ложноположительных срабатываний, т.е. исправил правильные слова. Получается, что алгоритм с моделью на грамм. тегах более консервативный и склонен реже классифицировать слово как ошибку, тогда как словный алгоритм поступает наоборот.\n",
    "\n",
    "Скорее всего, это объясняется природой данных, на которых мы оцениваемся. Дело в том, что словный алгоритм, как и было написано в задании, часто не учитывает конкретную форму слова и предлагает замену с правильным словом, но неправильной формой. Например, для опечатки *основая цель* словный алгоритм предсказывает правильное по семантике, но неверное по смыслу *основа*, а грамматический алгоритм наоборот: *сосновая* (форма правильная, слово — нет). Но при этом словный алгоритм часто ложно исправляет имена собственные. В целом, в данных намного больше кейсов, когда опечатка никак не влияет на определение формы, поэтому для данного датасета алгоритм, учитывающий грамматику, как будто нужен сильно меньше и, соответственно, справляется хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf9985",
   "metadata": {},
   "source": [
    "## 2.  Symspell (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392cc23",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм Symspell. Он похож на алгоритм Норвига, но проще и быстрее. Он основан только на одной операции - удалении символа. Описание алгоритма по шагам:\n",
    "\n",
    "1) Составляется словарь правильных слов  \n",
    "2) На основе словаря правильных слов составляется словарь удалений - для каждого правильного слова создаются все варианты удалений и создается словарь, где ключ - слово с удалением, а значение - правильное слово  (обратите внимание, что для одного удаления может быть несколько правильных слов!) \n",
    "3) При исправлении слова с опечаткой сначала само слово проверятся по словарю удаления, а затем для этого слова генерируются все варианты удалений, и каждый вариант проверяется по словарю удалений. Если в словаре удалений таким образом находится совпадение, то соответствующее ему правильное слово становится исправлением.\n",
    "Если совпадений несколько, то выбирается наиболее вероятное правильное слово  \n",
    "\n",
    "\n",
    "Оцените качество полученного алгоритма теми же тремя метриками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433bf457",
   "metadata": {},
   "source": [
    "### 1. Делаем словарь удалений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a298614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deletes_dict = defaultdict(set)\n",
    "\n",
    "\n",
    "def get_deletes_list(word):\n",
    "    if len(word) <= 1:\n",
    "        return []\n",
    "    return [word[:i] + word[i + 1:] for i in range(len(word))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b37d061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2679c638dc394f6893037e598c0f6ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121389 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of deletes dict: 1017239\n"
     ]
    }
   ],
   "source": [
    "# У нас уже есть готовый словарь из 1 задания\n",
    "for word in tqdm(vocab.keys()):\n",
    "    # Генерируем варианты удалений для правильного слова\n",
    "    deletes = get_deletes_list(word)\n",
    "    for d in deletes:\n",
    "        deletes_dict[d].add(word)\n",
    "\n",
    "print(f\"Size of deletes dict: {len(deletes_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d430ee62",
   "metadata": {},
   "source": [
    "### 2. Собственно алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ad33398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symspell_correction(word):\n",
    "    candidates = set()\n",
    "\n",
    "    # Проверяем само слово в словаре удалений\n",
    "    if word in deletes_dict:\n",
    "        candidates.update(deletes_dict[word])\n",
    "\n",
    "    # Генерируем удаления для ошибочного слова\n",
    "    typo_deletes = get_deletes_list(word)\n",
    "    for d in typo_deletes:\n",
    "        if d in deletes_dict:\n",
    "            candidates.update(deletes_dict[d])\n",
    "\n",
    "    # Если кандидатов нет, возвращаем исходное слово\n",
    "    if not candidates:\n",
    "        return word\n",
    "\n",
    "    # Выбираем наиболее вероятное слово из кандидатов по частоте в словаре\n",
    "    return max(candidates, key=lambda w: vocab[w])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9894d",
   "metadata": {},
   "source": [
    "### 3. Применение алгоритма к нашему датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5026f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_symspell_check(stanza_doc):\n",
    "    corrected_sentences = []\n",
    "\n",
    "    for sent in tqdm(stanza_doc.sentences):\n",
    "        pred_tokens = []\n",
    "\n",
    "        for token in sent.tokens:\n",
    "            word_obj = token.words[0]\n",
    "            text = word_obj.text\n",
    "            lower = text.lower()\n",
    "\n",
    "            # Пропускаем пунктуацию\n",
    "            if word_obj.upos == 'PUNCT':\n",
    "                pred_tokens.append(text)\n",
    "                continue\n",
    "\n",
    "            # Если слова нет в словаре - пытаемся исправить\n",
    "            if predict_mistaken(lower, vocab):\n",
    "                correction = symspell_correction(lower)\n",
    "                pred_tokens.append(correction)\n",
    "            else:\n",
    "                pred_tokens.append(lower)\n",
    "\n",
    "        # Собираем предложение обратно\n",
    "        corrected_sentences.append(\" \".join(pred_tokens))\n",
    "\n",
    "    return corrected_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ff8ef",
   "metadata": {},
   "source": [
    "### 4. Момент истины: запускаем и оцениваем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9c985fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SymSpell correction...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd2f81ccce646dc877bbd44a60561b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics (SymSpell):\n",
      "total_accuracy            | 0.7555\n",
      "fixed_mistakes            | 0.3802\n",
      "broken_correct_words      | 0.1759\n"
     ]
    }
   ],
   "source": [
    "print(\"Running SymSpell correction...\")\n",
    "preds_symspell = solve_symspell_check(doc_bad)\n",
    "\n",
    "metrics_symspell = calculate_metrics_stanza(doc_true, doc_bad, preds_symspell)\n",
    "\n",
    "print(\"\\nMetrics (SymSpell):\")\n",
    "for k, v in metrics_symspell.items():\n",
    "    print(f\"{k:<25} | {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a26c1",
   "metadata": {},
   "source": [
    "Как видим, с учётом того, что у нас достаточно маленький словарь, очень неплохо! И точно лучше, чем любой алгоритм с LM, хоть со словами, хоть с тегами. Скорость — отдельная песня, все предложения обработались меньше, чем за секунду, это в разы быстрее алгоритмов с вероятностями и дорогими перестановками, которые работают больше десяти минут."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70930cdc",
   "metadata": {},
   "source": [
    "# Задание 3 (2 балла)\n",
    "\n",
    "Используя любой из алгоритмов из семинара или домашки, детально проанализируйте получаемые ошибки. Улучшите алгоритм так, чтобы исправить ошибки. Улучшения в алгоритме должны быть общими, не привязанными к конкретным словам (например, словарь исключений не будет считаться). За каждое улучшение, которое исправляет 5+ ошибок вы получите 0.5 балла (максимум 2 в целом)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7ea06",
   "metadata": {},
   "source": [
    "### 1. Считаем ошибки в абсолютных значениях, чтобы было от чего отталкиваться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dcd0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_errors(doc_true, doc_bad, predicted_strs):\n",
    "    total_mistaken = 0\n",
    "    mistaken_fixed = 0\n",
    "    total_correct = 0\n",
    "    correct_broken = 0\n",
    "\n",
    "    for i in range(len(doc_true.sentences)):\n",
    "        true_tokens = [t.words[0].text.lower(\n",
    "        ) for t in doc_true.sentences[i].tokens if t.words[0].upos != 'PUNCT']\n",
    "        bad_tokens = [t.words[0].text.lower(\n",
    "        ) for t in doc_bad.sentences[i].tokens if t.words[0].upos != 'PUNCT']\n",
    "\n",
    "        pred_tokens = [t.strip('«»—…“”\".,?!:')\n",
    "                       for t in predicted_strs[i].split()]\n",
    "        pred_tokens = [t for t in pred_tokens if t]\n",
    "\n",
    "        min_len = min(len(true_tokens), len(bad_tokens), len(pred_tokens))\n",
    "\n",
    "        for j in range(min_len):\n",
    "            t = true_tokens[j]\n",
    "            b = bad_tokens[j]\n",
    "            p = pred_tokens[j]\n",
    "\n",
    "            if t != b:  # Изначально была ошибка\n",
    "                total_mistaken += 1\n",
    "                if t == p:  # Исправили\n",
    "                    mistaken_fixed += 1\n",
    "            else:  # Изначально было верно\n",
    "                total_correct += 1\n",
    "                if t != p:  # Сломали\n",
    "                    correct_broken += 1\n",
    "\n",
    "    return total_mistaken, mistaken_fixed, total_correct, correct_broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "609823fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word LM Results:\n",
      "Total Typos found: 1549\n",
      "Typos Fixed:       586\n",
      "Correct Broken:    1693\n"
     ]
    }
   ],
   "source": [
    "# Считаем для Word LM\n",
    "tm, fixed_word, tc, broken_word = get_absolute_errors(\n",
    "    doc_true, doc_bad, preds_word)\n",
    "print(f\"Word LM Results:\")\n",
    "print(f\"Total Typos found: {tm}\")\n",
    "print(f\"Typos Fixed:       {fixed_word}\")\n",
    "print(f\"Correct Broken:    {broken_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "471b9f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag LM Results:\n",
      "Total Typos found: 1549\n",
      "Typos Fixed:       401\n",
      "Correct Broken:    1496\n"
     ]
    }
   ],
   "source": [
    "# Считаем для Tag LM\n",
    "tm, fixed_tag, tc, broken_tag = get_absolute_errors(\n",
    "    doc_true, doc_bad, preds_tag)\n",
    "print(f\"Tag LM Results:\")\n",
    "print(f\"Total Typos found: {tm}\")\n",
    "print(f\"Typos Fixed:       {fixed_tag}\")\n",
    "print(f\"Correct Broken:    {broken_tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21991b3",
   "metadata": {},
   "source": [
    "### 2. Гибридный алгоритм\n",
    "\n",
    "Как мы видели при анализе результатов первого задания, словная модель часто правильно предсказывает слово, но ошибается с формой, тогда как модель на основе тегов умеет правильно выбирать форму, но либо промахивается со словом, либо, чаще всего, вовсе не видит ошибку. Попробуем реализовать гибридный алгоритм, в котором будет высчитываться объединённая вероятность Word LM и Tag LM (с некоторым весом каждого компонента). Тогда можно надеяться, что Word LM поможет предсказать правильное слово, а Tag LM — выбрать его правильную форму. Вес грамматической информации сделаем чуть выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1980238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_hybrid_check(stanza_doc, gamma=1.0, limit=None):\n",
    "    corrected_sentences = []\n",
    "\n",
    "    loop = stanza_doc.sentences[:limit] if limit else stanza_doc.sentences\n",
    "\n",
    "    for sent in tqdm(loop):\n",
    "        token_options = []\n",
    "\n",
    "        # Генерация кандидатов (как в задании 1)\n",
    "        for token in sent.tokens:\n",
    "            word_obj = token.words[0]\n",
    "            text = word_obj.text\n",
    "            lower = text.lower()\n",
    "\n",
    "            if word_obj.upos == 'PUNCT':\n",
    "                token_options.append([(text, None)])\n",
    "                continue\n",
    "\n",
    "            if predict_mistaken(lower, vocab):\n",
    "                preds = get_closest_hybrid_match(lower, X, vec)\n",
    "                candidates = [p[0] for p in preds]\n",
    "                candidates.append(lower)\n",
    "                candidates = list(set(candidates))\n",
    "\n",
    "                # Присваиваем теги кандидатам\n",
    "                cand_options = []\n",
    "                for cand in candidates:\n",
    "                    possible_tags = word_tags_cache.get(cand, Counter())\n",
    "                    if possible_tags:\n",
    "                        best_tag = possible_tags.most_common(1)[0][0]\n",
    "                        cand_options.append((cand, best_tag))\n",
    "                    else:\n",
    "                        original_tag = parse_conllu_features(\n",
    "                            word_obj.upos, word_obj.feats)\n",
    "                        cand_options.append((cand, original_tag))\n",
    "\n",
    "                token_options.append(cand_options)\n",
    "            else:\n",
    "                tag = parse_conllu_features(word_obj.upos, word_obj.feats)\n",
    "                token_options.append([(lower, tag)])\n",
    "\n",
    "        # Перебор комбинаций и гибридная оценка\n",
    "        best_sent_str = \"\"\n",
    "        best_score = -float('inf')\n",
    "\n",
    "        for p in itertools.product(*token_options):\n",
    "            words = [x[0] for x in p]\n",
    "\n",
    "            # Подготовка последовательностей (без None/пунктуации)\n",
    "            words_seq = [x[0] for x in p if x[1] is not None]\n",
    "            tags_seq = [x[1] for x in p if x[1] is not None]\n",
    "\n",
    "            log_p_word = compute_word_proba(words_seq)\n",
    "            log_p_tag = compute_tag_proba(tags_seq)\n",
    "\n",
    "            # Гибридная формула\n",
    "            final_score = log_p_word + (gamma * log_p_tag)\n",
    "\n",
    "            if final_score > best_score:\n",
    "                best_score = final_score\n",
    "                best_sent_str = \" \".join(words)\n",
    "\n",
    "        corrected_sentences.append(best_sent_str)\n",
    "\n",
    "    return corrected_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb19921",
   "metadata": {},
   "source": [
    "### 3. Запускаем и оцениваем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "961bf1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hybrid Correction...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04affb947dc4bfd8b8995fd2eee9d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics (Hybrid):\n",
      "total_accuracy            | 0.7488\n",
      "fixed_mistakes            | 0.3912\n",
      "broken_correct_words      | 0.1858\n",
      "\n",
      "Hybrid Model Results:\n",
      "Total misspellings found: 1549\n",
      "Misspelings Fixed:       606\n",
      "Correct Broken:    1575\n",
      "\n",
      "Improvement over Word LM:\n",
      "Additional Misspellings Fixed: 20\n",
      "Fewer Correct Broken:   118\n",
      "Total Net Improvement:  138\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Hybrid Correction...\")\n",
    "\n",
    "preds_hybrid = solve_hybrid_check(doc_bad, gamma=2.0)\n",
    "\n",
    "# Считаем метрики\n",
    "metrics = calculate_metrics_stanza(doc_true, doc_bad, preds_hybrid)\n",
    "print(\"\\nMetrics (Hybrid):\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k:<25} | {v:.4f}\")\n",
    "\n",
    "# Абсолютные ошибки\n",
    "tm, fixed_hybrid, tc, broken_hybrid = get_absolute_errors(\n",
    "    doc_true, doc_bad, preds_hybrid)\n",
    "\n",
    "print(f\"\\nHybrid Model Results:\")\n",
    "print(f\"Total misspellings found: {tm}\")\n",
    "print(f\"Misspelings Fixed:       {fixed_hybrid}\")\n",
    "print(f\"Correct Broken:    {broken_hybrid}\")\n",
    "\n",
    "# Сравнение\n",
    "diff_fixed = fixed_hybrid - fixed_word\n",
    "# Положительное число = сломали меньше слов\n",
    "diff_broken = broken_word - broken_hybrid\n",
    "\n",
    "print(\"\\nImprovement over Word LM:\")\n",
    "print(f\"Additional Misspellings Fixed: {diff_fixed}\")\n",
    "print(f\"Fewer Correct Broken:   {diff_broken}\")\n",
    "print(f\"Total Net Improvement:  {diff_fixed + diff_broken}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd6536",
   "metadata": {},
   "source": [
    "### 4. Смотрим, что улучшили"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de2cd97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Corrections (Hybrid vs Word LM):\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Симпатичнейшое шпионское устройство, такой себе гламурный фотоаппарат девушки Бонда - миниатюрная модель камеры Superheadz Clap Camera.\n",
      "Word LM:   ... чемпионское ...\n",
      "Hybrid:    ... шпионское ...\n",
      "Correct:   ... шпионское ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Отвественность за реализацию, естественно, лежит на контрактных пивоварах.\n",
      "Word LM:   ... контрактный ...\n",
      "Hybrid:    ... контрактных ...\n",
      "Correct:   ... контрактных ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Начальнег зажог павзрослому: всю предудущую неделю ходил покрытый прыщами, а с понедельника слег - ветрянка.\n",
      "Word LM:   ... павзрослому ...\n",
      "Hybrid:    ... по-взрослому ...\n",
      "Correct:   ... по-взрослому ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Подсаживаеться женшина - иностранка из Норвегии, она приглашает меня танцевать, оказывается что это место слишком крутое для меня, я загруживаюсь и больше в этот вечер не танцую...\n",
      "Word LM:   ... женщинам ...\n",
      "Hybrid:    ... женщина ...\n",
      "Correct:   ... женщина ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  И еще тут ряда на 4 назад какието малолетнии наркоманы, не понимая всю трагичность момента, начинают хихикать, потерянная молодеж.\n",
      "Word LM:   ... трагично ...\n",
      "Hybrid:    ... трагичность ...\n",
      "Correct:   ... трагичность ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Обълись пиццы и всячески ввеселились.\n",
      "Word LM:   ... пиццей ...\n",
      "Hybrid:    ... пиццы ...\n",
      "Correct:   ... пиццы ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Распрашивая иностранцев-гостей Питера о их впечатлении от русских, частым комментарием был тот факт, что все слишком сердитые и серьезные, никто не улыбается на улице.\n",
      "Word LM:   ... комментариям ...\n",
      "Hybrid:    ... комментарием ...\n",
      "Correct:   ... комментарием ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Расщифровать аудио мне так и не удалось.\n",
      "Word LM:   ... аудиокнига ...\n",
      "Hybrid:    ... аудио ...\n",
      "Correct:   ... аудио ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Припораты от варикоза\n",
      "Word LM:   ... припоминать ...\n",
      "Hybrid:    ... препараты ...\n",
      "Correct:   ... препараты ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Сочуствующие тут же бросились развивать тему, ( и так достаточно бредовую ), и доев свой грибной завтрак и покатавшись на радуге ребята засели за КРЕАТИФФ.\n",
      "Word LM:   ... сочувствующих ...\n",
      "Hybrid:    ... сочувствующие ...\n",
      "Correct:   ... сочувствующие ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Когда что-то не получаеться, падает самооценка, разрушаеться идеальный образ.\n",
      "Word LM:   ... разрушиться ...\n",
      "Hybrid:    ... разрушается ...\n",
      "Correct:   ... разрушается ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  он тряпки убирает там человек полуживой в хламину пяный!!\n",
      "Word LM:   ... мамин ...\n",
      "Hybrid:    ... хламину ...\n",
      "Correct:   ... хламину ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  фотка классная кстате, хоть и не по теме\n",
      "Word LM:   ... коротка ...\n",
      "Hybrid:    ... фотка ...\n",
      "Correct:   ... фотка ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Разговор чтото зашел про роботов и я долго и с увлечением рассказывал ей о философско-антропологической подоплеке многих фильмов типа Иск разум, Валли.\n",
      "Word LM:   ... подоплека ...\n",
      "Hybrid:    ... подоплеке ...\n",
      "Correct:   ... подоплеке ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  но сыро очень и ваще ат полный.\n",
      "Word LM:   ... сырой ...\n",
      "Hybrid:    ... сыро ...\n",
      "Correct:   ... сыро ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Первй день автобусная экскурсия, до биг бена не доехали.\n",
      "Word LM:   ... автобусной ...\n",
      "Hybrid:    ... автобусная ...\n",
      "Correct:   ... автобусная ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Отадала долг маме и выдала денег на прокорм.\n",
      "Word LM:   ... обладала ...\n",
      "Hybrid:    ... отдала ...\n",
      "Correct:   ... отдала ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Препораты для похудения на заказ\n",
      "Word LM:   ... препаратов ...\n",
      "Hybrid:    ... препараты ...\n",
      "Correct:   ... препараты ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Напректировали различные модели горок, решили сделать ее разноцветной.\n",
      "Word LM:   ... разноцветное ...\n",
      "Hybrid:    ... разноцветной ...\n",
      "Correct:   ... разноцветной ...\n",
      "------------------------------------------------------------\n",
      "Reason:    Fixed typo/hallucination\n",
      "Original:  Удалитъ анкету на однокласниках\n",
      "Word LM:   ... удалиться ...\n",
      "Hybrid:    ... удалить ...\n",
      "Correct:   ... удалить ...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 20 Corrections (Hybrid vs Word LM):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(preds_hybrid)):\n",
    "    t_tokens = [t.words[0].text.lower()\n",
    "                for t in doc_true.sentences[i].tokens if t.words[0].upos != 'PUNCT']\n",
    "    p_word_tokens = [t.strip('«»—…“”\".,?!:')\n",
    "                     for t in preds_word[i].split() if t.strip('«»—…“”\".,?!:')]\n",
    "    p_hybrid_tokens = [t.strip('«»—…“”\".,?!:')\n",
    "                       for t in preds_hybrid[i].split() if t.strip('«»—…“”\".,?!:')]\n",
    "\n",
    "    # Ищем случаи, где Hybrid лучше Word LM\n",
    "\n",
    "    min_len = min(len(t_tokens), len(p_word_tokens), len(p_hybrid_tokens))\n",
    "\n",
    "    for j in range(min_len):\n",
    "        true_w = t_tokens[j]\n",
    "        word_lm_w = p_word_tokens[j]\n",
    "        hybrid_w = p_hybrid_tokens[j]\n",
    "\n",
    "        improved = False\n",
    "        reason = \"\"\n",
    "\n",
    "        # Word LM ошибся, Hybrid прав\n",
    "        if word_lm_w != true_w and hybrid_w == true_w:\n",
    "            improved = True\n",
    "            reason = \"Fixed typo/hallucination\"\n",
    "\n",
    "        if improved:\n",
    "            print(f\"Reason:    {reason}\")\n",
    "            print(f\"Original:  {doc_bad.sentences[i].text}\")\n",
    "            print(f\"Word LM:   ... {word_lm_w} ...\")\n",
    "            print(f\"Hybrid:    ... {hybrid_w} ...\")\n",
    "            print(f\"Correct:   ... {true_w} ...\")\n",
    "            print(\"-\" * 60)\n",
    "            count += 1\n",
    "            break  # Одно исправление на предложение для наглядности\n",
    "\n",
    "    if count >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c6033c",
   "metadata": {},
   "source": [
    "Ура! Как видим, улучшения довольно существенные даже по сравнению со словным алгоритмом, который работал лучше грамматического. Нельзя сказать, что мы стали сильно лучше находить и исправлять ошибки (но +20 всё же есть), но мы точно стали меньше галлюцинировать, т.е. ломать правильное. Выходит, что ожидания оправдались, и мы смогли получить компромисс и взять лучшее от каждой модели: грамматическая модель позволяет меньше галлюцинировать, а словная — лучше находить реальные опечатки, причём вместе с грамматической даже лучше, чем самостоятельно."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
